{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"audio_allp_raw.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create unique id for each sentence\n",
    "\n",
    "df['sentence_uniq_id'] = df['doc_id'].apply(str) + df['paragraph_id'].apply(str) + df['sentence_id'].apply(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify last PUNCT on every sentence\n",
    "\n",
    "df[\"end_of_sentence\"] = False\n",
    "df[\"token_length\"] = 0\n",
    "\n",
    "current_id = df.loc[0,'sentence_uniq_id']\n",
    "for index, row in df.iterrows():\n",
    "    if row[\"sentence_uniq_id\"] != current_id:\n",
    "        current_id = row[\"sentence_uniq_id\"]\n",
    "        df.at[index-1, \"end_of_sentence\"] = True\n",
    "        df.at[index-1, \"token_length\"] = df.at[index-1, \"token_id\"] - 1\n",
    "\n",
    "#cast token_length to string\n",
    "df.token_length = pd.to_numeric(df.token_length, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# calculate dependency_length for each token\n",
    "\n",
    "df['dependency_length'] = df['token_id'] - df['head_token_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate jumlah dependency_lenght for each sentence\n",
    "\n",
    "current_id = df.loc[0,'sentence_uniq_id']\n",
    "sum_dependency_length = 0\n",
    "df[\"sum_dependency_length\"] = np.NaN\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    if row[\"sentence_uniq_id\"] == current_id:\n",
    "        if not row.end_of_sentence: # not counting the dependency_length of last PUNCT\n",
    "            sum_dependency_length += abs(row[\"dependency_length\"])\n",
    "    else:\n",
    "        df.at[index-1, \"sum_dependency_length\"] = sum_dependency_length\n",
    "        sum_dependency_length = 0\n",
    "        current_id = row[\"sentence_uniq_id\"]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average maju dan average mundur per kalimat\n",
    "\n",
    "# initialize value for average positive and negative value for each sentence\n",
    "df[\"avg_positive_dependency\"] = None\n",
    "df[\"avg_negative_dependency\"] = None\n",
    "\n",
    "# initialize value for count and sum\n",
    "list_positive_dependency = []\n",
    "list_negative_dependency = []\n",
    "\n",
    "# init current_sentence_id with first sentence_uniq_id\n",
    "current_sentence_id = df.loc[0,'sentence_uniq_id']\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    if row[\"sentence_uniq_id\"] == current_sentence_id:\n",
    "        # add element to list negative dependency\n",
    "        if row.dependency_length < 0:\n",
    "            list_negative_dependency.append(row.dependency_length)\n",
    "        else:\n",
    "            list_positive_dependency.append(row.dependency_length)\n",
    "    else:\n",
    "        # write averera dependency on data frame\n",
    "        df.at[index-1, \"avg_positive_dependency\"] = np.mean(list_positive_dependency)\n",
    "        df.at[index-1, \"avg_negative_dependency\"] = np.abs(np.mean(list_negative_dependency))\n",
    "        current_sentence_id = row[\"sentence_uniq_id\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.plotly as py\n",
    "import cufflinks as cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find Aveverage Dependency Length\n",
    "df[\"avg_dependency_length\"] = df.sum_dependency_length / (df.token_length - 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~endiyan/54.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from plotly.graph_objs import *\n",
    "\n",
    "py.iplot({\n",
    "    'data': [\n",
    "        Bar(**{\n",
    "            'x': df.loc[df.sum_dependency_length.notnull(),\"token_length\"], \n",
    "            'y': df.loc[df.sum_dependency_length.notnull(),\"avg_dependency_length\"],\n",
    "            'name' : 'AVG Dependency Length',\n",
    "            'type': 'bar'\n",
    "        })\n",
    "    ],\n",
    "    'layout': Layout(**{\n",
    "        'title': 'AVG Dependency Length'\n",
    "    })\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.graph_objs import *\n",
    "\n",
    "py.iplot({\n",
    "    'data': [\n",
    "        Bar(**{\n",
    "            'x': df.loc[df.sum_dependency_length.notnull(),\"token_length\"], \n",
    "            'y': df.loc[df.sum_dependency_length.notnull(),\"avg_dependency_length\"],\n",
    "            'name' : 'AVG Dependency Length',\n",
    "            'type': 'bar'\n",
    "        })\n",
    "    ],\n",
    "    'layout': Layout(**{\n",
    "        'title': 'AVG Dependency Length'\n",
    "    })\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.graph_objs import *\n",
    "df = df.loc[df.token_length.isin(['5','6','7','8','9'])]\n",
    "py.iplot({\n",
    "    'data': [\n",
    "        Bar(**{\n",
    "            'x': df.loc[df.sum_dependency_length.notnull(),\"token_length\"], \n",
    "            'y': df.loc[df.sum_dependency_length.notnull(),\"avg_dependency_length\"],\n",
    "            'name' : 'AVG Dependency Length',\n",
    "            'type': 'bar'\n",
    "        })\n",
    "    ],\n",
    "    'layout': Layout(**{\n",
    "        'title': 'AVG Dependency Length'\n",
    "    })\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "#liat jumlah sentence di setiap cluster\n",
    "#liat average dari average jarak dependensi di masing2 cluster\n",
    "#liat average maju dan mundur di masing masing cluster\n",
    "#bikin histogram 8 dan 9\n",
    "#bikin algo untuk ubah posisi kata ATAU\n",
    "#bikin algo untuk ubah posisi root ATAU\n",
    "#ngitung average dependency dengan nge-random depedendency root nya\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df[df.token_length > 50]['sentence'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
